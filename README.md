# Offline_Hindi_Voice_Assistant
# ğŸ—£ï¸ Offline Hindi Voice Assistant on Raspberry Pi 4 Model B

## ğŸ“Œ Project Overview

This project implements a fully offline Hindi Voice Assistant deployed on a Raspberry Pi platform.  
The system performs real-time speech recognition, command processing, and text-to-speech synthesis without using any cloud services.

The objective is to design a low-latency, privacy-preserving embedded speech pipeline suitable for edge deployment in low-resource environments.

## ğŸ‘©â€ğŸ’» About the Author

**Deepasri M**  
Electronics Engineering (VLSI Design and Technology)
Areas of Interest: VLSI Design, FPGA Design, Hardware Acceleration, Signal Processing, Edge AI  

Focused on building performance-optimized, hardware-aware intelligent systems for real-time applications.

## ğŸ‘¥ Team

- Deepasri M â€“ System Architecture, Embedded Integration, Audio Pipeline Design  
- Sowmyavalli S â€“ Model Deployment, Optimization
- Sahana S -  Testing & Validation  

## ğŸ¯ Problem Statement
Offline, Privacy-Preserving Hindi Voice Assistant on Raspberry Pi

## Objective
Develop a low-latency, privacy-preserving voice assistant on an Arm-based SBC (e.g., Raspberry Pi) that processes Hindi voice commands entirely offline. The assistant should handle local queries (time, weather, etc.) using on-device ASR and TTS.

## Project Description
Students will build an embedded speech pipeline performing:

  Speech-to-text using a lightweight ASR model (e.g., Coqui STT or fine-tuned wav2vec2 for Hindi).
  Command parsing and intent recognition in Python.
  Text-to-speech responses using local TTS (eSpeak-NG or Festival).
  End-to-end on the Raspberry Pi CPU with no cloud dependency.
  
## Key Requirements

# Hardware:
  Raspberry Pi 5 or 4 (or similar Arm SBC).
  USB microphone.
  Speaker via 3.5 mm jack or HDMI.
Where possible, aim to use the CPU without additional accelerators/hats. Solutions that are well-optimised through use of Quantisation, KleidiAI, and appropriate model selection - and therefore able to run entirely on CPU - are of great interest.

# Software:
  Python with PyAudio for audio I/O.
  Coqui STT or fine-tuned wav2vec2 for ASR, or similar.
  eSpeak-NG or Festival for TTS.
  Custom Python logic for intent recognition and command execution.

# Performance Targets
  Sub-2-second response time per command.
  Accurate recognition for 10â€“15 Hindi commands.
  Robust, fully offline operation.

# Deliverables
  Source code for the full voice assistant pipeline.
  Documentation of any model fine-tuning / optimization steps.
  Demo video showing responses to multiple commands.
  Short report on architecture, challenges in Hindi ASR/TTS, and performance metrics.

# Learning Outcomes
  Hands-on experience with embedded speech AI and offline ASR/TTS.
  Understanding challenges of regional language processing.
  Integrating ASR, simple NLP/intent logic, and TTS on a constrained platform.

## ğŸ—ï¸ System Architecture

### ğŸ”¹ Hardware
- Raspberry Pi 4  
- USB Microphone  
- Speaker  

### ğŸ”¹ Software Stack
- Python 3.9  
- Vosk (Offline Speech Recognition Engine)  
- eSpeak (Text-to-Speech Engine)  
- ALSA / PulseAudio (Audio Interface)  
## âš™ï¸ Working Principle

1. Audio is captured through the microphone at 16kHz sampling rate.  
2. Speech is converted to text using the Vosk Hindi ASR model.  
3. Commands are processed locally using rule-based intent parsing.  
4. The system generates an appropriate response.  
5. eSpeak synthesizes and outputs the response through the speaker.  

All processing is executed locally on the Raspberry Pi without any internet connectivity.

## ğŸš€ Features

- Fully offline operation  
- Real-time Hindi speech recognition  
- Low-latency response  
- Lightweight and optimized for ARM architecture  
- Privacy-preserving design  
- No external API dependency  

## ğŸ“Š Performance Metrics

| Parameter | Value |
|------------|--------|
| Average Response Time | ~1â€“1.5 seconds |
| CPU Usage | ~45â€“60% |
| Memory Usage | ~300â€“400 MB |
| Sampling Rate | 16 kHz |

*Performance may vary depending on model size and hardware configuration.*

## ğŸ“‚ Project Structure

offline-hindi-assistant/
â”‚
â”œâ”€â”€ assistant.py
â”œâ”€â”€ readme.txt
â”œâ”€â”€ requirements.txt
â””â”€â”€ setup.sh

## ğŸ”§ Installation & Setup
1ï¸âƒ£ Clone Repository
git clone https://github.com/Deepa-0408/hindi_voice_assistant.git
cd offline-hindi-assistant

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

3ï¸âƒ£ Download Hindi Vosk Model

Download the Hindi model from the official Vosk website and place it inside the (models/) directory.

# link
https://alphacephei.com/vosk/models/vosk-model-small-hi-0.22.zip

4ï¸âƒ£ Run the Application
python assistant.py

## ğŸ§  Applications

1. Rural and low-connectivity environments

2. Privacy-sensitive institutional setups

3. Smart home embedded systems

4. Assistive technology for elderly users

5. Educational voice-based interfaces

## ğŸ”® Future Enhancements

1. Model quantization for lower memory footprint

2. FPGA-based speech acceleration

3. Wake-word detection integration

4. Multilingual support

5. Edge AI co-processor integration

## ğŸ“ˆ Technical Significance

This project demonstrates:

1. Real-time embedded AI implementation

2. Edge deployment of speech models

3. Resource-constrained system optimization

4. Practical application of signal processing and embedded programming

It bridges the gap between AI algorithms and hardware-aware deployment, making it suitable for both academic and industrial exploration.
